{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import torch.optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "import os\n",
    "import warnings\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining neural network for note classification.\n",
    "class GaussianNoiseLayer(nn.Module):\n",
    "    def __init__(self, std=0.1):\n",
    "        super(GaussianNoiseLayer, self).__init__()\n",
    "        self.std = std\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            noise = torch.randn_like(x) * self.std\n",
    "            return x + noise\n",
    "        return x\n",
    "\n",
    "class FreqToNote(nn.Module):\n",
    "    def __init__(self, window_size, hidden_layer):\n",
    "        super(FreqToNote, self).__init__()\n",
    "\n",
    "        self.window_size = window_size # 1<<12\n",
    "        self.hidden_layer = hidden_layer # 100\n",
    "\n",
    "        self.linear1 = nn.Linear(window_size, hidden_layer, dtype=torch.float32)\n",
    "        self.linear3= nn.Linear(hidden_layer, hidden_layer, dtype=torch.float32)\n",
    "        self.activation = nn.LeakyReLU()\n",
    "        self.dropOut=nn.Dropout(0.25)\n",
    "        self.gaussian=GaussianNoiseLayer(std=0.1)\n",
    "        self.linear2 = nn.Linear(hidden_layer, 12, dtype=torch.float32)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.gaussian(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        for i in range(2):\n",
    "            x=self.linear3(x)\n",
    "            x= tf.abs(x).detach().numpy()\n",
    "        x = self.linear2(x)\n",
    "        x = self.sigmoid(magnitude)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a custom dataset to load a dataframe into a pytorch dataset.\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, frequencies, notes):\n",
    "        self.frequencies = torch.tensor(frequencies, dtype=torch.float32)\n",
    "        self.notes = torch.tensor(notes, dtype=torch.float32)  # Adjust the data type as needed\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.frequencies)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = {\n",
    "            'frequencies': self.frequencies[idx],\n",
    "            'notes': self.notes[idx]\n",
    "        }\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bit of preprocessing.\n",
    "pathToProcessedData='data/'\n",
    "\n",
    "frequencies=[]\n",
    "notes=[]\n",
    "\n",
    "def parse_complex(complex_str):\n",
    "\n",
    "    if complex_str==\"0+-0i\":\n",
    "        return [0,0]\n",
    "    complex_str = complex_str.replace('i', 'j')\n",
    "    num=complex(complex_str)\n",
    "    return [num.real, num.imag]\n",
    "\n",
    "def formatCSV():\n",
    "    with open(pathToProcessedData+\"complex.csv\", 'r') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        for line in csv_reader:\n",
    "            ar=[parse_complex(ele) for ele in line].flatten()\n",
    "            frequencies.append([ele for ele in ar])\n",
    "                \n",
    "    with open(pathToProcessedData+\"out.csv\", 'r') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        for line in csv_reader:\n",
    "            notes.append([int(ele) for ele in line])\n",
    "\n",
    "formatCSV()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 332195199 is out of bounds for dimension 0 with size 117924",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Shiyan Liu\\GitHub\\string-protagonist\\ml\\py\\evaluation.ipynb Cell 5\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Shiyan%20Liu/GitHub/string-protagonist/ml/py/evaluation.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m FreqToNote(\u001b[39m2\u001b[39m\u001b[39m*\u001b[39m(\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m (\u001b[39m1\u001b[39m\u001b[39m<<\u001b[39m\u001b[39m11\u001b[39m)), \u001b[39m300\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Shiyan%20Liu/GitHub/string-protagonist/ml/py/evaluation.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m fullDataSet\u001b[39m=\u001b[39mCustomDataset(frequencies, notes)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Shiyan%20Liu/GitHub/string-protagonist/ml/py/evaluation.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m train_dataset, test_dataset \u001b[39m=\u001b[39m train_test_split(fullDataSet, test_size\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m, random_state\u001b[39m=\u001b[39;49m\u001b[39m42\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Shiyan%20Liu/GitHub/string-protagonist/ml/py/evaluation.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m train_loader \u001b[39m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Shiyan%20Liu/GitHub/string-protagonist/ml/py/evaluation.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m test_loader \u001b[39m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py:184\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m global_skip_validation \u001b[39m=\u001b[39m get_config()[\u001b[39m\"\u001b[39m\u001b[39mskip_parameter_validation\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 184\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    186\u001b[0m func_sig \u001b[39m=\u001b[39m signature(func)\n\u001b[0;32m    188\u001b[0m \u001b[39m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_split.py:2672\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2668\u001b[0m     cv \u001b[39m=\u001b[39m CVClass(test_size\u001b[39m=\u001b[39mn_test, train_size\u001b[39m=\u001b[39mn_train, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m   2670\u001b[0m     train, test \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(cv\u001b[39m.\u001b[39msplit(X\u001b[39m=\u001b[39marrays[\u001b[39m0\u001b[39m], y\u001b[39m=\u001b[39mstratify))\n\u001b[1;32m-> 2672\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\n\u001b[0;32m   2673\u001b[0m     chain\u001b[39m.\u001b[39mfrom_iterable(\n\u001b[0;32m   2674\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m arrays\n\u001b[0;32m   2675\u001b[0m     )\n\u001b[0;32m   2676\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_split.py:2674\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2668\u001b[0m     cv \u001b[39m=\u001b[39m CVClass(test_size\u001b[39m=\u001b[39mn_test, train_size\u001b[39m=\u001b[39mn_train, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m   2670\u001b[0m     train, test \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(cv\u001b[39m.\u001b[39msplit(X\u001b[39m=\u001b[39marrays[\u001b[39m0\u001b[39m], y\u001b[39m=\u001b[39mstratify))\n\u001b[0;32m   2672\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\n\u001b[0;32m   2673\u001b[0m     chain\u001b[39m.\u001b[39mfrom_iterable(\n\u001b[1;32m-> 2674\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m arrays\n\u001b[0;32m   2675\u001b[0m     )\n\u001b[0;32m   2676\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\__init__.py:357\u001b[0m, in \u001b[0;36m_safe_indexing\u001b[1;34m(X, indices, axis)\u001b[0m\n\u001b[0;32m    355\u001b[0m     \u001b[39mreturn\u001b[39;00m _array_indexing(X, indices, indices_dtype, axis\u001b[39m=\u001b[39maxis)\n\u001b[0;32m    356\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 357\u001b[0m     \u001b[39mreturn\u001b[39;00m _list_indexing(X, indices, indices_dtype)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\__init__.py:211\u001b[0m, in \u001b[0;36m_list_indexing\u001b[1;34m(X, key, key_dtype)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(compress(X, key))\n\u001b[0;32m    210\u001b[0m \u001b[39m# key is a integer array-like of key\u001b[39;00m\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m [X[idx] \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m key]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\__init__.py:211\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(compress(X, key))\n\u001b[0;32m    210\u001b[0m \u001b[39m# key is a integer array-like of key\u001b[39;00m\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m [X[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m key]\n",
      "\u001b[1;32mc:\\Users\\Shiyan Liu\\GitHub\\string-protagonist\\ml\\py\\evaluation.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Shiyan%20Liu/GitHub/string-protagonist/ml/py/evaluation.ipynb#X13sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Shiyan%20Liu/GitHub/string-protagonist/ml/py/evaluation.ipynb#X13sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     sample \u001b[39m=\u001b[39m {\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Shiyan%20Liu/GitHub/string-protagonist/ml/py/evaluation.ipynb#X13sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mfrequencies\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfrequencies[idx],\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Shiyan%20Liu/GitHub/string-protagonist/ml/py/evaluation.ipynb#X13sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mnotes\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnotes[idx]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Shiyan%20Liu/GitHub/string-protagonist/ml/py/evaluation.ipynb#X13sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     }\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Shiyan%20Liu/GitHub/string-protagonist/ml/py/evaluation.ipynb#X13sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m sample\n",
      "\u001b[1;31mIndexError\u001b[0m: index 332195199 is out of bounds for dimension 0 with size 117924"
     ]
    }
   ],
   "source": [
    "#Initializing model and training parameters.\n",
    "model = FreqToNote(2*(1 + (1<<11)), 300)\n",
    "fullDataSet=CustomDataset(frequencies, notes)\n",
    "train_dataset, test_dataset = train_test_split(fullDataSet, test_size=0.1, random_state=42)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "optimizer=torch.optim.Adam(model.parameters())\n",
    "scheduler=torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.8)\n",
    "lossFunction=torch.nn.BCELoss()\n",
    "\n",
    "epochs=10\n",
    "trainLosses=[]\n",
    "testLosses=[]\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        inputs, labels =batch[\"frequencies\"], batch[\"notes\"]\n",
    "        outputs = model(inputs)\n",
    "        loss = lossFunction(outputs, labels)\n",
    "        trainLosses.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "model.eval()\n",
    "correct_predictions = 0\n",
    "total_samples = 0\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        inputs, labels = batch[\"frequencies\"], batch[\"notes\"]\n",
    "        outputs = model(inputs)\n",
    "        loss = lossFunction(outputs, labels)\n",
    "        testLosses.append(loss.item())\n",
    "\n",
    "fig, axs = plt.subplots(2)\n",
    "axs[0].plot(range(len(trainLosses)), trainLosses)\n",
    "axs[1].plot(range(len(testLosses)), testLosses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(\n",
    "    model,\n",
    "    torch.randn(1, model.window_size),\n",
    "    \"freq_predictor.onnx\",\n",
    "    opset_version=13,\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"output\"]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
